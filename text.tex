\documentclass[a4paper, 12pt]{article}

\usepackage[ngerman]{babel} 
\usepackage[T1]{fontenc}
\usepackage{amsfonts} 
\usepackage{setspace}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{titling}
\usepackage{hyperref}
\usepackage{csquotes} % for \textquote{}
% REMINDER: USE IEEEeqnarray* FOR ALINGMENTS%
\usepackage{IEEEtrantools}
\usepackage{stix}

\newcommand*{\puffer}{\text{ }\text{ }\text{ }\text{ }}
\newcommand*{\gedanke}{\textbf{-- }}
\newcommand*{\gap}{\text{ }}
\newcommand*{\setDef}{\gap|\gap}
% Hab länger gebraucht um zu realisieren, dass das ne gute Idee wäre
\newcommand*{\R}{\mathbb R}
\newcommand*{\N}{\mathbb N}
\newcommand*{\Z}{\mathbb Z}
\newcommand*{\grad}{\text{grad}}
\newcommand*{\J}{\textbf{J}}
\newcommand*{\He}{\textbf{H}}
\newcommand*{\smi}{\text{-}}
\newcommand*{\Co}{\mathcal C^1}
\newcommand*{\Ct}{\mathcal C^2}
\newcommand*{\todo}{\textit{\dots TODO \dots}}

% ¯\_(ツ)_/¯
\usepackage{tikz}
\newcommand{\shrug}[1][]{%
\begin{tikzpicture}[baseline,x=0.8\ht\strutbox,y=0.8\ht\strutbox,line width=0.125ex,#1]
\def\arm{(-2.5,0.95) to (-2,0.95) (-1.9,1) to (-1.5,0) (-1.35,0) to (-0.8,0)};
\draw \arm;
\draw[xscale=-1] \arm;
\def\headpart{(0.6,0) arc[start angle=-40, end angle=40,x radius=0.6,y radius=0.8]};
\draw \headpart;
\draw[xscale=-1] \headpart;
\def\eye{(-0.075,0.15) .. controls (0.02,0) .. (0.075,-0.15)};
\draw[shift={(-0.3,0.8)}] \eye;
\draw[shift={(0,0.85)}] \eye;
% draw mouth
\draw (-0.1,0.2) to [out=15,in=-100] (0.4,0.95); 
\end{tikzpicture}}


\pagestyle{plain}
\allowdisplaybreaks

\setlength{\droptitle}{-14em}
%\setlength{\jot}{12pt}

\title{\scshape Mathe C Klausurzettel}
\author{\scshape Henri Heyden\\\small stu240825}
\date{}

\begin{document}
\maketitle
\subsection*{Analysis}
\subsubsection*{Integrierbarkeit}
\text{\scshape Riemann Summe}\\
Sei \(f : [a,b] \rightarrow \R\), seien \((x, \xi)\) Partition und Stützstellen aus \([a,b]\).\\
Dann nennen wir \(R(f,x,\xi) := \sum_{i=1}^n (x_i - x_{i-1}) \cdot f(\xi_i)\) Riemann Summe. \\ \\
\text{\scshape Integrierbarkeit}\\
Wir nennen \(f\) integrierbar, wenn\\\(\exists R_0 \in \R \forall \epsilon > 0 \exists \delta > 0 \forall(x,\xi) \in \text{PS}(a,b,\delta): |R(f,x,\xi) - R_0| < \epsilon\) gilt. \\
Das Integral ist eindeutig, schreibe \(\int_{a}^{b} f\) oder \(\int f\) hierfür. \\
Wir schreiben auch \(\int f(x)\text dx := \int f\) \\
Ist \(f\) integrierbar, dann kann man das Integral mit einer Beliebigen Folge an \((x_n,\xi_n)_n\) finden wessen Feinheit den Limes 0 hat, sodass die Riemann-Summe konvergiert. \\
\(f\) ist genau dann integrierbar, wenn für alle 2 solcher Folgen ihre Differenz immer zu 0 konvergiert. \\ \\
\text{\scshape Stetig und Kompakt} \\
Eine Funktion \(f\): \\
\dots ist stetig in \(x \in \text{dom}(f)\), wenn alle Funktionslimetes zu \(x\) gleich sind.\\
\dots ist beschränkt, wenn ihre Domain eine obere und untere Schranke hat. \\
\dots ist abgeschlossen, wenn das komplement ihrer Domain offen ist. \\
\dots ist kompakt, wenn sie beschränkt und abgeschlossen ist. \\
Ist eine Funktion kompakt stetig, dann ist sie gleichmäßig stetig und somit integrierbar. \\ \\
\text{\scshape Abschätzungen} \\
Für \(f \le g\) gilt: \(\int f \le \int g\). \\
Es gilt: \((b-a) \cdot \inf(f) \le \int_{a}^{b}f \le (b-a) \cdot \sup(f)\)
\subsubsection*{Integrationstechniken}
\text{\scshape Hauptsatz der Differenzialrechnung} \\
Schreibe \([\phi]_u^v := \phi(v) - \phi(u)\) \\
Sei \(f,F: \Omega \rightarrow \R\) so, dass \(F' = f\) gilt. \\
Dann gilt: \(\int f = F(\sup(\Omega)) - F(\inf(\Omega)) = F(b) - F(a) = [F]_a^b\) für \(\Omega = [a,b]\).
\pagebreak \\
\text{\scshape Stammfunktionen} \\ \\
\begin{tabular}{ c | c | c | c }
    \hline
    Domain & \(f(x)\) & \(F(x)\) & args \\
    \hline
    \(\R\) & \(c\) & \(cx\) & \(c \in \R\) \\
    \(\R\) & \(\sum_{k=0}^{n}a_kx^k\) & \(\sum_{k=0}^{n}\frac{a_k}{k+1}x^{k+1}\) & \(a_0 \dots a_n \in \R\) \\
    \(\R_{> 0}\) & \(x^{-1}\) & \(\ln(x)\) & \\
    \(\R\) & \(b^x\) & \(\frac{b^x}{\ln(b)}\) & \(b \in \R_{>0} \setminus \{1\}\) \\
    \(\R_{> 0}\) & \(\log_b(x)\) & \(\frac{x\ln(x) - x}{\ln(b)}\) & \(b \in \R_{>0} \setminus \{1\}\) \\
    \(]\smi 1, 1[\) & \(\frac{1}{\sqrt{1-x^2}}\) & arcsin\((x)\) & \\
    \(\R\) & \(\frac{1}{1+x^2}\) & arctan\((x)\) & \\
\end{tabular} \\ \\ \\
\text{\scshape Partielle Integration} \\
Für \(f,g : [a,b] \rightarrow \R\) gilt: \(\int_{a}^{b}fg' = [fg]_a^b - \int_{a}^{b}f'g\) \\ \\
\text{\scshape Substitution} \\
Für \(f\) stetig reel und \(\phi\) stetig differenzierbar reel mit \(u,v \in \text{dom}(\phi)\),\\
sodass \([u,v] \subseteq \text{dom}(\phi)\) und \(\phi^\rightarrow([u,v]) \subseteq \text{dom}(f)\) ist, gilt:
\[\int_{\phi(u)}^{\phi(v)}f = \int_{u}^{v}(f \circ \phi) \cdot \phi'\]
\subsubsection*{Uneigentliche Integrale}
\text{\scshape Integral über \(x^{-\alpha}\)} \\
1) \(\forall \alpha > 1: \int_{1}^{+\infty} x^{-\alpha} \text d x = \frac{1}{\alpha - 1}\). \puffer Für \(\alpha \in ]0,1]\) divergiert das Integral. \\
2) \(\forall \alpha \in ]0,1[: \int_{0}^{1}x^{-\alpha} \text d x = \frac{1}{1 - \alpha}\). \puffer Für \(\alpha \ge 1\) divergiert das Integral. \\ \\
\text{\scshape Vergleichskriterium} \\
Seien \(f,g: [a,b[ \rightarrow \R\) integrierbar über alle Teilintervalle und \(|f| \le g\). \\
Konvergiert das uneigentliche Integral über \(g\), dann konvergiert das uneigentliche Integral über \(f\). \\ \\
\text{\scshape Integralkriterium} \\
Warnung nicht im Skript, trotzdem leichtes Argument. \\
Sei \(p \in \Z\) und \(f : [p, \infty[ \rightarrow \R_{> 0}\) monoton fallend. \\
Dann ist \(f\) integrierbar genau dann, wenn \(\sum_{n = p}^{\infty} f(n)\) konvergiert. \\
Zur Motivation betrachte \(\sum_{n = p}^{\infty} f(n)\) als obere Schranke und Annäherung des Integrals mittels Riemann Summe mit gleichmäßiger Feinheit 1.
\subsection*{Analytische Grundstrukturen}
\subsubsection*{Metrische Räume}
\text{\scshape Metrik} \\
Eine Metrik ist eine Funktion \(d : M^2 \rightarrow \R_{\ge 0}\) mit folgenden Eigentschaften:\\
1) \(d(x,y) = 0 \Longleftrightarrow x = y\) \puffer \puffer \gap \gap (positive Definitheit) \\
2) \(d(x,y) = d(y,x)\) \puffer \puffer \puffer \puffer \gap \gap \gap (Symmetrie) \\
3) \(d(x,y) \le d(x,z) + d(z,y)\) \puffer (Dreiecksungleichung) \\ \\
\text{\scshape Eigenschaften der Metrik} \\
Für Metrische Räume gelten alle analytischen Gesetze und Sätze aus MatheB nur mit jeder Metrik nicht nur der Betragsmetrik.
Somit sind Begriffe wir Stetigkeit, Limes, Kompaktheit, Funktionslimes etc. äquivalent.
\subsubsection*{Normierte Räume}
\text{\scshape Norm} \\
Sei \(V\) Vektorraum, dann ist \(||\cdot||\) Norm auf \(V\), wenn folgende Gesetze gelten:\\
1) \(||v|| = 0 \Longleftrightarrow v = 0\) \\
2) \(||\lambda|| = |\lambda| \cdot ||v||\) \\
3) \(||u+v|| \le ||u|| + ||v||\) \\ \\
\text{\scshape Beispielnormen über \(\R^n\)} \\
Sei \(k \in \N_{> 0}\), dann ist \(||\cdot||_k : \R^n \rightarrow \R, v \mapsto \sqrt[k]{\sum_{i=1}^{n}|v_i|}\) Norm \\
Die Funktion \(||\cdot||_\infty : \R^n \rightarrow \R, v \mapsto \max_{i \in [n]}|v_i|\) ist Norm \\ \\
\text{\scshape Eigenschaften der Norm} \\
Es gilt \(||-v|| = ||v||\) \\
Außerdem ist \(V^2 \rightarrow \R_{\ge 0}, (u,v) \mapsto ||u-v||\) Metrik. Somit lassen sich analytische Grundbegriffe für Vektorräume komposieren und alle Eigentschaften der Metrischen Räume für jene Metrik anwenden. \\
Normen sind stetig. Also \(||\cdot||\) ist eine stetige Funktion. \\ \\
\text{\scshape Äquivalenz von Normen} \\
Seien \((V, ||\cdot||)\) und \((V, ||\cdot||')\) normierte Räume. Wir nennen \(||\cdot||\) und \(||\cdot||'\) äquivalent, wenn folgendes gilt: \(\exists \alpha,\beta > 0: \forall v \in V: \alpha ||v|| \le ||v||' \le \beta||v||\) \\
Umgebungen über äquivalente Normen sind äquivalent, genau wie Konvergenz mit den gleichen Limetes, Stetigkeiten und Kompaktheiten. \\
Auf endlich dimensionalen Vektorräumen sind alle Normen äquivalent.
\subsection*{Differentation im Mehrdimensionalen}
Es seien \(V, W\) Vektorräume über \(\R\), \(\Omega \subseteq V\).
\subsubsection*{Differenzierbarkeit}
\text{\scshape Definiton der Differenzierbarkeit} \\
Wir nennen \(f : \Omega \rightarrow W\) differenzierbar in \(v\), wenn \[\exists \phi \in \text L(V,W): \lim_{\tilde v \rightarrow v} \frac{||f(\tilde v) - (f(v) + \phi(\tilde v - v))||_W}{||\tilde v - v||_V} = 0_\R\]
gilt. Dann nennen wir \(\phi\) Ableitung von \(f\) und schreiben \(D(f) := \phi\). Offenbar da \(\phi\) linear stetig ist, existiert eine Matrix für \(\phi\). Folgende Definiton ist äquivalent: \[\exists \phi \in \text L(V,W): \lim_{h \rightarrow 0_V} \frac{||f(v + h) - (f(v) + \phi(h))||_W}{||h||_V} = 0_\R\]
Gilt \(V = W = \R\), dann ist die Definiton äquivalent zur Differenzierbarkeit im bekannten Sinne.
\subsubsection*{Ableitungsregeln}
Ist \(f\) differenzierbar, dann sind alle Komponentenfunktionen von \(f\) \((V,\R)\)-differenzierbar. \\ \\
\text{\scshape Kombinationssätze} \\
Für \(\lambda : \Omega \rightarrow \R\), \(f,g : \Omega \rightarrow V\) differenzierbar gelten folgende Regeln:\\
1) \(D(f+g) = D(f) + D(g)\) \\
2) \(D(\lambda f) = \lambda D(f)\) \\
3) \(D\left(\frac{1}{\lambda}\right) = \frac{D(\lambda)}{\lambda^2}\) \\
4) \(D\left(\frac{f}{\lambda}\right) = \frac{\lambda D(f) - fD(\lambda)}{\lambda^2}\) \\
\subsubsection*{Partielle Ableitungen}
Seien \(\Omega \subseteq \R^n, f : \Omega \rightarrow \R^d\), \(i \in [n], j \in [d], v \in \Omega\).
\text{\scshape Partielle Differenzierbarkeit} \\
Wir nennen \(f_j\) partiell differenzierbar in \(v\) nach der i-ten Variable, wenn \(f_{j,v,i}\) in \(v_i\) differenzierbar ist.\\
Wir definieren \(\partial_i f_j(v) := f_{j,v,i}'(v_i)\). \pagebreak \\
\text{\scshape Beispiel} \\
Sei \(f: \R \times \R_{\ge 0} \rightarrow \R^4, (x,y) \mapsto \left(x+y, xy, x^2+3y-6, -2\sqrt{y}\right)\). \\
Dann gilt:\\
\(\partial_1f_2(x,y) = y\), \puffer
\(\partial_1f_3(x,y) = 2x\), \puffer
\(\partial_1f_4(x,y) = 0\), \\
\(\partial_2f_1(x,y) = 1\), \puffer
\(\partial_2f_3(x,y) = 3\) \\ \\
\text{\scshape Gradient und Jacobi-Matrix} \\
Wir definieren den Gradienten von \(f_j\) als \(\grad_{f_j}(v) := (\partial_1f_j(v), \dots, \partial_nf_j(v))\). \\
Des Weiteren definieren wir die Jacobi-Matrix von \(f\):\[\J_f(v) := \begin{bmatrix}
    \partial_1f_1(v) & \hdots & \partial_nf_1(v) \\
    \vdots & & \vdots \\
    \partial_1f_d(v) & \hdots & \partial_nf_d(v)
\end{bmatrix}\] Somit gilt: \[\J_f(v) = \begin{bmatrix}
    \grad_{f_1}(v) \\
    \vdots \\
    \grad_{f_d}(v)
\end{bmatrix}\]
Ist \(f\) differenzierbar in \(v\), dann ist \(\J_f(v)\) Ableitung von \(f\), aber Achtung: Vollständige partielle Differenzierbarkeit impliziert NICHT totale Differenzierbarkeit! \\ \\
\text{\scshape Totale Differenzierbarkeit aus Partieller Differenzierbarkeit} \\
Ist \(f\) vollständig partiell differenzierbar und alle Ableitung sind stetig, dann ist \(f\) total differenzierbar. \\ \\
\text{\scshape \(\Co\)-Funktionen und \(\Ct\)-Funktionen} \\
Wir nennen \(f: \Omega \rightarrow \R^d\) eine \(\Co\)-Funktion, wenn sie vollständig stetig partiell differenzierbar ist. Somit ist also eine \(\Co\)-Funktion total differenzierbar. \\
\(f\) ist \(\Co\)-Funktion, wenn all ihre Komponentenfunktionen aus Kombinationen von Projektionen stetiger differenzierbaren eindimensionalen Funktionen bestehen. \\
Wir nennen \(f: \Omega \rightarrow \R\) eine \(\Ct\)-Funktion, wenn sie eine \(\Co\)-Funktion ist, und \(\forall i \in [n]: \partial_if\) stetig partiell differenzierbar ist. \\
Dies ist äquivalent dazu, dass \(\grad_f\) eine \(\Co\)-Funktion ist. \\Die partielle
Ableitung von \(\partial_i f\) nach der \(j\)-ten Variable bezeichnen wir mit \(\partial_j\partial_if\). \\ \\
\text{\scshape Hesse-Matrix} \\
Sei \(f: \Omega \rightarrow \R\) eine \(\Ct\)-Funktion, wir definieren die Hesse-Matrix von \(f\) als: \[\He_f := \begin{bmatrix}
    \partial_1\partial_1f(v) & \hdots & \partial_1\partial_nf(v) \\
    \vdots & & \vdots \\
    \partial_n\partial_1f(v) & \hdots & \partial_n\partial_nf(v)
\end{bmatrix}\] offenbar gilt: \(\He_f(v) = (\J_{\grad_f}(v))^{\top}\), denn die Spalten der Hesse - Matrix sind die
Gradienten der Komponentenfunktionen von \(\grad_f\).\\
Die Transposition ist auch nicht nötig, da die Hesse-Matrix symmetrisch ist.\\ Das heißt es gilt: \(\forall i,j\in[n]: \partial_i\partial_jf = \partial_j\partial_if\).
\subsubsection*{Lokale Extremstellen}
\todo
\subsection*{Stochastik}
\end{document}